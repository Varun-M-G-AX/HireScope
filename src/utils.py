"""
utils.py â€“ shared helpers for HireScope

â€¢ Reads OPENAI_API_KEY from env (HF Secret)
â€¢ Uses persistent ChromaDB in /data/chroma_store on HF
â€¢ Falls back to ./chroma_store locally (or inâ€‘memory if /data isn't writable)
â€¢ GPTâ€‘4o rÃ©sumÃ© summariser
â€¢ Candidateâ€‘ID generator
"""
import os, re
from datetime import datetime
import streamlit as st
import openai, chromadb
from chromadb.utils import embedding_functions

# â”€â”€ 1. Secure API key â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("âŒ OPENAI_API_KEY missing. Add it in Space âžœ Settings âžœ Secrets.")
    st.stop()
openai.api_key = OPENAI_API_KEY

# â”€â”€ 2. Choose persistent directory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_LOCAL_DIR = "./chroma_store"
HF_DATA_DIR       = "/data/chroma_store"          # Hugging Face Docker volume

USE_HF_DIR = bool(os.getenv("SPACE_ID") or os.getenv("HF_SPACE_ID"))
PERSIST_DIR = os.getenv("CHROMA_DB_DIR",
                        HF_DATA_DIR if USE_HF_DIR else DEFAULT_LOCAL_DIR)

# â”€â”€ 3. Create (or gracefully skip) the directory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def get_chroma_client():
    try:
        os.makedirs(PERSIST_DIR, exist_ok=True)
        st.info(f"ðŸ“‚ Using persistent Chroma directory: {PERSIST_DIR}")
        return chromadb.PersistentClient(path=PERSIST_DIR)
    except PermissionError:
        st.warning(f"âš ï¸ No write access to {PERSIST_DIR}. "
                   "Falling back to inâ€‘memory ChromaDB (data will reset on restart).")
        return chromadb.Client()   # ephemeral

chroma_client = get_chroma_client()

def get_collection():
    return chroma_client.get_or_create_collection(
        name="resumes",
        embedding_function=embedding_functions.OpenAIEmbeddingFunction(
            api_key=OPENAI_API_KEY,
            model_name="text-embedding-3-large",
        )
    )
collection = get_collection()

# â”€â”€ 4. GPTâ€‘4o rÃ©sumÃ© summariser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def summarize_resume(raw: str) -> str:
    prompt = f"""
Return the rÃ©sumÃ© as structured **plain text** (NOT JSON) like:

Name: ...
Email: ...
Phone: ...
Location: ...
Skills: python, sql, ...
Languages: english, ...
Certifications: ...
Education:
  â€¢ Degree at University
Work Experience:
  â€¢ Role at Company (dates) â€“ short summary
Latest Role: ...

RÃ©sumÃ©:
\"\"\"{raw[:3000]}\"\"\""""
    resp = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.2,
    )
    return resp.choices[0].message.content.strip()

# â”€â”€ 5. Candidateâ€‘ID helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_candidate_id(name: str) -> str:
    clean = re.sub(r"[^a-zA-Z0-9]", "", name.lower())
    return f"{clean}_{datetime.now():%Y%m%d%H%M%S}"
