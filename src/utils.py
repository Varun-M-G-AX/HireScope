# utils.py â€“ shared helpers for HireScope

import os, re
from datetime import datetime
import streamlit as st
import openai, chromadb
from chromadb.utils import embedding_functions

# â”€â”€ 1. Load API key â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    st.error("âŒ OPENAI_API_KEY missing. Add it in Space âžœ Settings âžœ Secrets.")
    st.stop()
openai.api_key = OPENAI_API_KEY

# â”€â”€ 2. Chroma persistence location â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DEFAULT_LOCAL_DIR = "./chroma_store"
HF_DATA_DIR       = "/data/chroma_store"

USE_HF_DIR   = bool(os.getenv("SPACE_ID") or os.getenv("HF_SPACE_ID"))
PERSIST_DIR  = os.getenv("CHROMA_DB_DIR", HF_DATA_DIR if USE_HF_DIR else DEFAULT_LOCAL_DIR)

@st.cache_resource
def get_chroma_client():
    try:
        os.makedirs(PERSIST_DIR, exist_ok=True)
        st.info(f"ðŸ“‚ Using persistent Chroma directory: {PERSIST_DIR}")
        return chromadb.PersistentClient(path=PERSIST_DIR)
    except PermissionError:
        st.warning(f"âš ï¸ No write access to {PERSIST_DIR}. Falling back to inâ€‘memory ChromaDB.")
        return chromadb.Client()

chroma_client = get_chroma_client()

def get_collection():
    return chroma_client.get_or_create_collection(
        name="resumes",
        embedding_function=embedding_functions.OpenAIEmbeddingFunction(
            api_key=OPENAI_API_KEY,
            model_name="text-embedding-3-large"
        )
    )

collection = get_collection()

# â”€â”€ 3. Load prompt_2.md into memory â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource
def load_prompt_template(path="src/prompt_2.md"):
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception as e:
        st.error(f"âš ï¸ Could not read prompt_2.md: {e}")
        return ""

PROMPT_TEMPLATE = load_prompt_template()

# â”€â”€ 4. GPTâ€‘4o JSON rÃ©sumÃ© parser â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def summarize_resume(raw: str) -> str:
    prompt = f"{PROMPT_TEMPLATE}\n\nRÃ©sumÃ©:\n{raw[:3000]}"
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"âŒ Error calling OpenAI: {e}")
        return "{}"

# â”€â”€ 5. Candidate ID helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_candidate_id(name: str) -> str:
    clean = re.sub(r"[^a-zA-Z0-9]", "", name.lower())
    return f"{clean}_{datetime.now():%Y%m%d%H%M%S}"